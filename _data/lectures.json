{"misc":[{
	"youtube_id": "mbkbMvMxLmg",
	"title": "From principal components to puppyslugs",
	"date": "6/21/2017",
	"thumbnail": "/images/classes/misc/thumbnail_01.png",
	"dropbox": "",
	"bookmarks": [
		{"title":"Generative models", "m":4, "s":10, "disp":"4:10"},
		{"title":"Why sampling images is hard", "m":5, "s":58, "disp":"5:58"},
		{"title":"Principal component analysis", "m":9, "s":57, "disp":"9:57"},
		{"title":"Eigenfaces", "m":15, "s":15, "disp":"15:15"},
		{"title":"Neural networks", "m":29, "s":28, "disp":"29:28"},
		{"title":"Representation learning and feature extraction", "m":48, "s":26, "disp":"48:26"},
		{"title":"Autoencoders", "m":61, "s":31, "disp":"1:01:31"},
		{"title":"Generative adversarial networks", "m":67, "s":31, "disp":"1:07:31"},
		{"title":"BEGAN, InfoGAN, DiscoGAN, StackGAN, ArtGAN", "m":77, "s":44, "disp":"1:17:44"},
		{"title":"Deep generator networks", "m":81, "s":50, "disp":"1:21:50"},
		{"title":"Conditional GANs (pix2pix)", "m":86, "s":25, "disp":"1:26:25"},
		{"title":"CycleGANs, horse2zebra", "m":94, "s":27, "disp":"1:34:27"},
		{"title":"Skip-thought vectors and WaveNets", "m":97, "s":11, "disp":"1:37:11"},
		{"title":"Class synthesis, deepdream, and puppyslugs", "m":101, "s":08, "disp":"1:41:08"}
	],
	"summary": [
		"Generative modeling of images",
		"Principal component analysis and Eigenfaces",
		"Autoencoders, generative adversarial networks, pix2pix",
		"Deepdream, class synthesis, and puppyslugs",
		"Taught by <a href=\"https://twitter.com/genekogan\">@genekogan</a>"
	]}
],
"opendot":[{
	"youtube_id": "yHOmMCY589Y",
	"title": "Why machine learning for artists",
	"date": "11/21/2016",
	"thumbnail": "/images/classes/opendot/thumbnail_01.png",
	"dropbox": "https://www.dropbox.com/s/fxz3pbyoj2se91j/opendot_11.21_01.mp4?dl=1",
	"bookmarks": [
		{"title":"Introduction, about the class", "m":0, "s":0, "disp":"0:00"},
		{"title":"Neither democrats nor dictators; Why ML for artists", "m":8, "s":4, "disp":"8:04"},
		{"title":"Early history of AI & ML through 1980s", "m":15, "s":37, "disp":"15:37"},
		{"title":"Emergence of deep learning", "m":31, "s":48, "disp":"31:48"},
		{"title":"Critical issues in AI", "m":52, "s":20, "disp":"52:20"},
		{"title":"Neural networks and the brain analogy", "m":66, "s":36, "disp":"1:06:36"},
		{"title":"Showcase of art projects using ML", "m":68, "s":59, "disp":"1:08:59"},
		{"title":"Resources + ml4a.github.io", "m":86, "s":46, "disp":"1:26:46"}
	],
	"summary": [
		"Overview of the class, why ML for artists",
		"Micro-history of AI, machine learning, and deep learning",
		"Some examples of artistic ML works",
		"Resources + ml4a.github.io"
	]	
},{
	"youtube_id": "sAs0YUwxAoY",
	"title": "Neural networks",
	"date": "11/21/2016",
	"thumbnail": "/images/classes/opendot/thumbnail_02.png",
	"dropbox": "https://www.dropbox.com/s/x1mozy0kxn75g2m/opendot_11.21_02.mp4?dl=1",
	"bookmarks": [
		{"title":"Supervised and unsupervised machine learning", "m":0, "s":0, "disp":"0:00"},
		{"title":"Introduction to neurons and neural networks", "m":2, "s":48, "disp":"2:48"},
		{"title":"An example: classifying images of handwritten digits", "m":14, "s":23, "disp":"14:23"},
		{"title":"Visualizing the weights during training", "m":19, "s":46, "disp":"19:46"},
		{"title":"The big picture: generalizing supervised learning and performance applications", "m":35, "s":9, "disp":"35:09"}
	],
	"summary": [
		"How neural networks work",
		"Visualizing neural networks during training",
		"General applications of neural nets"
	]
},{
	"youtube_id": "Y3UuIER66FQ",
	"title": "Real-time ML for performance",
	"date": "11/21/2016",
	"thumbnail": "/images/classes/opendot/thumbnail_03.png",
	"dropbox": "https://www.dropbox.com/s/qlk1v6db0r6yxd1/opendot_11.21_03.mp4?dl=1",
	"bookmarks": [
		{"title":"Machine learning for real-time performance, music, and art", "m":0, "s":0, "disp":"0:00"},
		{"title":"Basic Wekinator + Processing app", "m":10, "s":19, "disp":"10:19"},
		{"title":"Sound example: controlling an FM Synth", "m":56, "s":37, "disp":"56:37"},
		{"title":"FaceOSC controlling FM Synth", "m":73, "s":43, "disp":"1:13:43"},
		{"title":"Putting it altogether! FaceOSC controlling Ableton", "m":86, "s":58, "disp":"1:26:58"},
		{"title":"FaceOSC controlling AudioUnits", "m":89, "s":25, "disp":"1:29:25"}
	],
	"summary": [
		"Basic Processing + Wekinator application",
		"Using neural nets to control audio synths",
		"Making music with a face tracker"
	]
},{
	"youtube_id": "vCIDk-bS_zQ",
	"title": "Convolutional neural networks + t-SNE",
	"date": "11/22/2016",
	"thumbnail": "/images/classes/opendot/thumbnail_04.png",
	"dropbox": "https://www.dropbox.com/s/r6ud3p7ry0dmcak/opendot_11.22_01.mp4?dl=1",
	"bookmarks": [
		{"title":"Recap of day 1", "m":0, "s":0, "disp":"0:00"},
		{"title":"Limitations of ordinary neural nets", "m":5, "s":46, "disp":"5:46"},
		{"title":"How convolutional neural networks work", "m":11, "s":13, "disp":"11:13"},
		{"title":"Convnet demo", "m":24, "s":27, "disp":"24:27"},
		{"title":"Probing and visualizing convnet activations", "m":38, "s":22, "disp":"38:22"},
		{"title":"Transfer learning and reverse image search demo", "m":44, "s":50, "disp":"44:50"},
		{"title":"Organizing and visualizing image sets with t-SNE", "m":53, "s":51, "disp":"53:51"},
		{"title":"Visualizing text documents with t-SNE", "m":57, "s":7, "disp":"57:07"},
		{"title":"Audio t-SNE", "m":59, "s":28, "disp":"59:28"},
		{"title":"Assigning image t-SNEs to grids", "m":61, "s":2, "disp":"1:01:02"}
	],
	"summary": [
		"How convnets work",
		"Activations are useful; reverse image search",
		"t-SNE for organizing image collections",
		"t-SNE in text and audio domains"
	]
},{
	"youtube_id": "L3OOWqir-9g",
	"title": "Applications of t-SNE",
	"date": "11/23/2016",
	"thumbnail": "/images/classes/opendot/thumbnail_05.png",
	"dropbox": "https://www.dropbox.com/s/535vx1ua4jox605/opendot_11.23_01.mp4?dl=1",
	"bookmarks": [
		{"title":"About Image-to-Image translation paper", "m":0, "s":0, "disp":"0:00"},
		{"title":"Make your own live image classifier with ConvnetOSC and Wekinator", "m":11, "s":10, "disp":"11:10"},
		{"title":"Make your own Audio t-SNE in openFrameworks", "m":22, "s":12, "disp":"22:12"},
		{"title":"Bohemian Rhapsody segmented t-SNE", "m":33, "s":0, "disp":"33:00"},
		{"title":"Class discussion of techniques, style transfer in other domains", "m":35, "s":22, "disp":"35:22"}
	],
	"summary": [
		"Discussion of image-to-image translation",
		"Transfer learning with convnets",
		"How to make audio t-SNEs"
	]
},{
	"youtube_id": "E2r3_oddwEc",
	"title": "Applications of deep learning",
	"date": "11/23/2016",
	"thumbnail": "/images/classes/opendot/thumbnail_06.png",
	"dropbox": "https://www.dropbox.com/s/4730zse93xy3o22/opendot_11.23_02.mp4?dl=1",
	"bookmarks": [
		{"title":"Generative visual applications of convnets", "m":0, "s":0, "disp":"0:00"},
		{"title":"Class visualization and deepdream", "m":2, "s":28, "disp":"2:28"},
		{"title":"Deepdream implementations and code", "m":10, "s":14, "disp":"10:14"},
		{"title":"Style transfer & examples", "m":12, "s":12, "disp":"12:12"},
		{"title":"Video style transfer", "m":21, "s":29, "disp":"21:29"},
		{"title":"Special cases of style transfer and image-to-image mapping", "m":26, "s":6, "disp":"26:06"},
		{"title":"Recurrent neural networks and LSTMs", "m":32, "s":28, "disp":"32:28"},
		{"title":"Dense captioning and sequence-based applications", "m":46, "s":50, "disp":"46:50"}
	],
	"summary": [
		"Generative images; Deepdream and style transfer",
		"Image to image mapping",
		"LSTMs, text generation, and dense captioning"
	]
}],
"neural-aesthetic":[{
	"youtube_id": "kc2XOUEyhDM",
	"title": "Machine learning for artists",
	"date": "7/4/2016",
	"thumbnail": "/images/classes/neural-aesthetic/thumbnail_01.png",
	"dropbox": "https://www.dropbox.com/s/vz5qlb6ee2ffjhp/neural%20aesthetic%20%40%20schoolofma%20--%2001%20machine%20learning%20for%20artists.mp4?dl=1",
	"bookmarks": [
		{"title":"Introduction, policies, syllabus, resources + ml4a", "m":0, "s":0, "disp":"0:00"},
		{"title":"Fun with Meapsoft and music information retrieval", "m":43, "s":03, "disp":"43:03"},
		{"title":"What is machine learning?", "m":58, "s":42, "disp":"58:42"},
		{"title":"AI hype cycles", "m":70, "s":23, "disp":"1:10:23"},
		{"title":"Objectives of AI (HAL in 2001: A Space Odyssey)", "m":76, "s":45, "disp":"1:16:45"},
		{"title":"ML for media art, Wekinator", "m":81, "s":04, "disp":"1:21:04"},
		{"title":"Deep learning art applications: Deepdream and Style transfer", "m":84, "s":22, "disp":"1:24:22"},
		{"title":"Survey of recent artworks, and alt-AI exhibition pieces", "m":93, "s":37, "disp":"1:33:37"}
	],
	"summary": [
		"Hype and history  of machine learning",
		"Overview of neural networks",
		"Applications of neural networks",
		"Survey of recent ML-inspired artworks"
	]	
},{
	"youtube_id": "ED-_-JzvvFk",
	"title": "Neural networks",
	"date": "7/5/2016",
	"thumbnail": "/images/classes/neural-aesthetic/thumbnail_02.png",
	"dropbox": "https://www.dropbox.com/s/ln5ylmvfm6xku6q/neural%20aesthetic%20%40%20schoolofma%20--%2002%20neural%20networks.mp4?dl=1",
	"bookmarks": [
		{"title":"From biological to artificial neurons", "m":1, "s":32, "disp":"1:32"},
		{"title":"Defining artificial neurons and activation functions", "m":13, "s":10, "disp":"13:10"},
		{"title":"A simple neural network and forward pass", "m":23, "s":58, "disp":"23:58"},
		{"title":"Classifying images of handwritten digits", "m":31, "s":48, "disp":"31:48"},
		{"title":"Visualizing the weights of a neural net", "m":38, "s":21, "disp":"38:21"},
		{"title":"Overview of convolutional neural networks", "m":60, "s":38, "disp":"1:00:38"},
		{"title":"End-to-end demo of a convnet", "m":99, "s":29, "disp":"1:39:29"},
		{"title":"Interpreting convnets and visual applications", "m":130, "s":13, "disp":"2:10:13"}
	],
	"summary": [
		"How neural networks work",
		"Overview of convolutional neural nets",
		"Visualizing convnets"
	]
},{
	"youtube_id": "euMXlFJlSTQ",
	"title": "Convolutional neural networks + t-SNE",
	"date": "7/6/2016",
	"thumbnail": "/images/classes/neural-aesthetic/thumbnail_03.png",
	"dropbox": "https://www.dropbox.com/s/bcqcmgh4uegek8d/neural%20aesthetic%20%40%20schoolofma%20--%2003%20convnets%20%2B%20t-SNE.mp4?dl=1",
	"bookmarks": [
		{"title":"Review of neural networks", "m":9, "s":45, "disp":"9:45"},
		{"title":"Shortcomings of ordinary neural nets", "m":24, "s":16, "disp":"24:16"},
		{"title":"Convolutional layers", "m":36, "s":13, "disp":"36:13"},
		{"title":"Visualizing what convnet layers learn", "m":51, "s":07, "disp":"51:07"},
		{"title":"Deepdream, style transfer, variational autoencoders", "m":54, "s":12, "disp":"54:12"},
		{"title":"Overview of recurrent neural nets", "m":71, "s":21, "disp":"1:11:21"},
		{"title":"t-SNE embedding of images in 2d", "m":84, "s":58, "disp":"1:24:58"},
		{"title":"Embedding text articles with t-SNE (e.g. political ideologies)", "m":102, "s":52, "disp":"1:42:52"},
		{"title":"Audio t-SNE: embedding audio samples in 2d", "m":113, "s":22, "disp":"1:53:22"},
		{"title":"Tutorial: how to make a t-SNE of images", "m":140, "s":19, "disp":"2:20:19"}
	],
	"summary": [
		"How convolutional neural networks work",
		"Overview of recurrent neural networks",
		"Embedding images, text, and audio with t-SNE",
		"Image t-SNE tutorial"
	]
},{
	"youtube_id": "l8lJ8hxHyyc",
	"title": "Trolley problem, discussion {poor audio}",
	"date": "7/7/2016",
	"thumbnail": "/images/classes/neural-aesthetic/thumbnail_04.png",
	"dropbox": "https://www.dropbox.com/s/f1sr8ogeih5zeuq/neural%20aesthetic%20%40%20schoolofma%20--%2004%20trolley%20problem%2C%20ethics.mp4?dl=1",
	"bookmarks": [
		{"title":"Robots as our \"children\"", "m":0, "s":0, "disp":"0:00"},
		{"title":"The trolley problem", "m":17, "s":33, "disp":"17:33"},
		{"title":"Descartes: animals are machines", "m":46, "s":10, "disp":"46:10"},
		{"title":"Review of week 1", "m":50, "s":50, "disp":"50:50"},
		{"title":"Assignment + introduction to Wekinator, review resources", "m":64, "s":50, "disp":"1:04:50"},
		{"title":"Democratizing AI research (Keras) + discussion", "m":79, "s":06, "disp":"1:19:06"}
	],
	"summary": [
		"Trolley problem {poor audio}",
		"Ethical dilemmas and critical issues in AI",
		"Democratizing AI research"
	]
},{
	"youtube_id": "JVD7MudjF10",
	"title": "Wekinator, real-time applications of neural nets",
	"date": "7/18/2016",
	"thumbnail": "/images/classes/neural-aesthetic/thumbnail_09.png",
	"dropbox": "https://www.dropbox.com/s/enudiynnm9kqrt7/neural%20aesthetic%20%40%20schoolofma%20--%2009%20wekinator%20examples%2C%20modules.mp4?dl=1",
	"bookmarks": [
		{"title":"The big picture: neural nets map volumes", "m":0, "s":0, "disp":"0:00"},
		{"title":"Real-time and interactive media-driven uses of neural nets", "m":9, "s":34, "disp":"9:34"},
		{"title":"Controlling audio units with OSC", "m":22, "s":20, "disp":"22:20"},
		{"title":"Transfer learning from trained convnet", "m":31, "s":32, "disp":"31:32"},
		{"title":"KinectOSC -> Wekinator -> Processing sketch", "m":36, "s":58, "disp":"36:58"},
		{"title":"Microphone audio -> Wekinator -> openFrameworks glitchy visuals", "m":69, "s":26, "disp":"1:09:26"},
		{"title":"Making your own image classifier via ConvnetOSC -> Wekinator", "m":144, "s":0, "disp":"2:24:00"}
	],
	"summary": [
		"Real-time interaction with ML via Wekinator",
		"Wekinator examples and modules",
		"Transfer learning with ConvnetOSC and Wekinator"
	]
},{
	"youtube_id": "--eZESmJBXQ",
	"title": "Applications of convnets",
	"date": "7/19/2016",
	"thumbnail": "/images/classes/neural-aesthetic/thumbnail_10.png",
	"dropbox": "https://www.dropbox.com/s/lomjxbz3vokmfhl/neural%20aesthetic%20%40%20schoolofma%20--%2010%20convnet%20applications.mp4?dl=1",
	"bookmarks": [
		{"title":"Review how convnets work", "m":0, "s":0, "disp":"0:00"},
		{"title":"Visualizing and interpreting learned features", "m":21, "s":54, "disp":"21:54"},
		{"title":"Why the activations are valuable", "m":27, "s":46, "disp":"27:46"},
		{"title":"Image embeddings with t-SNE", "m":36, "s":38, "disp":"36:38"},
		{"title":"Class visualization and Deepdream", "m":53, "s":37, "disp":"53:37"},
		{"title":"Style transfer", "m":85, "s":12, "disp":"1:25:12"},
		{"title":"Special cases of style transfer: video, real-time, colorless", "m":102, "s":14, "disp":"1:42:14"},
		{"title":"Image analogies, neural-doodle, super-resolution, assistive", "m":109, "s":10, "disp":"1:49:10"},
		{"title":"Colorizing black & white images", "m":115, "s":27, "disp":"1:55:27"},
		{"title":"Deep convolutional generative adversarial networks", "m":117, "s":34, "disp":"1:57:34"},
		{"title":"Tutorial: neural-style in terminal instance", "m":123, "s":01, "disp":"2:03:01"}
	],
	"summary": [
		"Visualizing convnets and interpreting activations",
		"Deepdream, style transfer, and other convnet visual applications",
		"neural-style tutorial"
	]
},{
	"youtube_id": "vrBh9Nd1QP4",
	"title": "Recurrent neural networks",
	"date": "7/20/2016",
	"thumbnail": "/images/classes/neural-aesthetic/thumbnail_11.png",
	"dropbox": "https://www.dropbox.com/s/2gv770ublilrn3k/neural%20aesthetic%20%40%20schoolofma%20--%2011%20recurrent%20neural%20networks.mp4?dl=1",
	"bookmarks": [
		{"title":"Feedforward vs. recurrent", "m":0, "s":0, "disp":"0:00"},
		{"title":"RNNs predicting characters", "m":7, "s":31, "disp":"7:31"},
		{"title":"Text generation: Shakespeare, XML, LaTeX, recipes, TED, dictionaries, sci-fi, emojis, Trump", "m":12, "s":18, "disp":"12:18"},
		{"title":"Architectures: sequence to sequence, captioning images", "m":32, "s":0, "disp":"32:00"},
		{"title":"Dense-captioning images", "m":46, "s":41, "disp":"46:41"},
		{"title":"Sequence to unit and misc applications", "m":52, "s":42, "disp":"52:42"},
		{"title":"Sound/music: sequencing audio and MIDI", "m":61, "s":50, "disp":"1:01:50"}
	],
	"summary": [
		"How recurrent neural networks work",
		"Applications and artworks with RNNs and LSTMs",
		"Dense captioninig and advanced architectures"
	]
},{
	"youtube_id": "QES5UgIO9B4",
	"title": "Game AI & reinforcement learning",
	"date": "7/21/2016",
	"thumbnail": "/images/classes/neural-aesthetic/thumbnail_12.png",
	"dropbox": "https://www.dropbox.com/s/g3neicmofe8r65y/neural%20aesthetic%20%40%20schoolofma%20--%2012%20reinforcement%20learning%20%2B%20game%20AI.mp4?dl=1",
	"bookmarks": [
		{"title":"The Glass Bead Game + DeepMind", "m":0, "s":0, "disp":"0:00"},
		{"title":"What is reinforcement learning?", "m":9, "s":42, "disp":"9:42"},
		{"title":"Learning how to play Atari games", "m":17, "s":10, "disp":"17:10"},
		{"title":"Convnets controlling joysticks", "m":33, "s":07, "disp":"33:07"},
		{"title":"RL IRL: motor learning to balance a pole", "m":46, "s":50, "disp":"46:50"},
		{"title":"Games and tree search: Tic tac toe + Chess", "m":49, "s":22, "disp":"49:22"},
		{"title":"Putting it all together: AlphaGo", "m":62, "s":32, "disp":"1:02:32"}
	],
	"summary": [
		"Reinforcement learning",
		"Convnets playing Atari games",
		"DeepBlue and AlphaGo"
	]
}],
"itp-S16":[{
	"youtube_id": "z0bynQjEpII",
	"title": "Introduction, neural networks",
	"date": "3/24/2016",
	"thumbnail": "/images/classes/itp-S16/thumbnail_01.png",
	"dropbox": "https://www.dropbox.com/s/jkgo87c2fe6zcmr/ml4a%20%40%20itp-nyu%20--%2001%20introduction%2C%20neural%20networks.mp4?dl=1",
	"bookmarks": [
		{"title":"Introduction", "m":0, "s":0, "disp":"0:00"}, 
		{"title":"Machine learning and neural networks", "m":11, "s":03, "disp":"11:03"}, 
		{"title":"Demo forward pass and MNIST", "m":23, "s":45, "disp":"23:45"}, 
		{"title":"Visualizing the weights", "m":52, "s":17, "disp":"52:17"}, 
		{"title":"MNIST/CIFAR confusion matrix", "m":62, "s":50, "disp":"1:02:50"}, 
		{"title":"Convolutional neural network demo", "m":81, "s":52, "disp":"1:21:52"}, 
		{"title":"Applications of convnets", "m":103, "s":58, "disp":"1:43:58"}
	],
	"summary": [
		"Introduction to machine learning",
		"The whole class in 1 hour",
		"Introduction to neural networks"
	]	
},{
	"youtube_id": "lKmkt5LEDS8",
	"title": "Applications, Wekinator",
	"date": "3/31/2016",
	"thumbnail": "/images/classes/itp-S16/thumbnail_02.png",
	"dropbox": "https://www.dropbox.com/s/6gg635cbxazsp56/ml4a%20%40%20itp-nyu%20--%2002%20applications%2C%20wekinator.mp4?dl=1",
	"bookmarks": [
		{"title":"Review of neural networks", "m":7, "s":50, "disp":"7:50"}, 
		{"title":"Walkthrough of a practical ML experiment with ofxLearn", "m":10, "s":47, "disp":"10:47"}, 
		{"title":"Code resources for setting up ordinary neural nets", "m":22, "s":15, "disp":"22:15"}, 
		{"title":"Intro to Wekinator", "m":28, "s":12, "disp":"28:12"}, 
		{"title":"Basic walkthrough and simple example", "m":37, "s":30, "disp":"37:30"}, 
		{"title":"More complex example w/ FaceOSC", "m":64, "s":52, "disp":"1:04:52"}, 
		{"title":"FaceTracker -> happy/sad colors", "m":73, "s":26, "disp":"1:13:26"}, 
		{"title":"Leap Motion input", "m":86, "s":27, "disp":"1:26:27"}, 
		{"title":"Classification of webcam pixels", "m":101, "s":0, "disp":"1:41:00"}, 
		{"title":"Dynamic time warping with bark coefficients", "m":117, "s":24, "disp":"1:57:24"}, 
		{"title":"Critical reading", "m":126, "s":39, "disp":"2:06:39"}
	],
	"summary": [
		"Practical resources for simple neural nets",
		"Implementing neural nets in openFrameworks",
		"Introduction to Wekinator"
	]
},{
	"youtube_id": "z6k_RMKExlQ",
	"title": "Convolutional neural networks",
	"date": "4/7/2016",
	"thumbnail": "/images/classes/itp-S16/thumbnail_03.png",
	"dropbox": "https://www.dropbox.com/s/9beww4qyq2nyqhe/ml4a%20%40%20itp-nyu%20--%2003%20convolutional%20neural%20networks.mp4?dl=1",
	"bookmarks": [
		{"title":"[Nick Hubbard] Trolley problem", "m":8, "s":15, "disp":"8:15"}, 
		{"title":"'Animals are machines' - Rene Descartes", "m":20, "s":30, "disp":"20:30"}, 
		{"title":"Wekinator custom outputs + Ableton", "m":25, "s":10, "disp":"25:10"}, 
		{"title":"Wekinator + Audio Units (mac)", "m":40, "s":48, "disp":"40:48"}, 
		{"title":"Wekinator + audioreactive Jitter", "m":43, "s":17, "disp":"43:17"}, 
		{"title":"Kinect + gesture recognition options", "m":52, "s":38, "disp":"52:38"}, 
		{"title":"Limitations of ordinary neural nets", "m":63, "s":16, "disp":"1:03:16"}, 
		{"title":"Convolutional and pooling layers", "m":84, "s":51, "disp":"1:24:51"}, 
		{"title":"Convnets: the whole pipeline", "m":109, "s":24, "disp":"1:49:24"}
	],
	"summary": [
		"Critical issues in AI",
		"More advanced Wekinator examples",
		"Introduction to convolutional neural networks"
	]
},{
	"youtube_id": "V0glxY6fHTY",
	"title": "Convnet applications",
	"date": "4/14/2016",
	"thumbnail": "/images/classes/itp-S16/thumbnail_04.png",
	"dropbox": "https://www.dropbox.com/s/taaxxu6ebth78ay/ml4a%20%40%20itp-nyu%20--%2004%20convnet%20applications.mp4?dl=1",
	"bookmarks": [
		{"title":"Stranger Visions and reconstructing data", "m":8, "s":10, "disp":"8:10"},
		{"title":"Reviewing convnets", "m":13, "s":34, "disp":"13:34"},
		{"title":"Interpreting and visualizing activations", "m":40, "s":0, "disp":"40:00"},
		{"title":"Occlusion demo, localization/compression, deconvolution", "m":50, "s":12, "disp":"50:12"},
		{"title":"Image synthesis and Deepdream", "m":69, "s":53, "disp":"1:09:53"},
		{"title":"Style transfer", "m":91, "s":03, "disp":"1:31:03"},
		{"title":"Transfer learning (Convnet -> Wekinator)", "m":108, "s":20, "disp":"1:48:20"},
		{"title":"t-SNE on convnet activations (and text)", "m":117, "s":20, "disp":"1:57:20"}
	],
	"summary": [
		"Interpreting and visualizing convnet activations",
		"Image class synthesis, deepdream, style transfer",
		"Transfer learning",
		"t-SNE for visualizing images, text"
	]
},{
	"youtube_id": "u18NVUvSEsU",
	"title": "Recurrent neural networks",
	"date": "4/21/2016",
	"thumbnail": "/images/classes/itp-S16/thumbnail_05.png",
	"dropbox": "https://www.dropbox.com/s/ap5tqz56n0m1fu0/ml4a%20%40%20itp-nyu%20--%2005%20recurrent%20neural%20networks.mp4?dl=1",
	"bookmarks": [
		{"title":"Review feedforward neural networks", "m":2, "s":19, "disp":"2:19"},
		{"title":"Feedforward vs. recurrence", "m":7, "s":38, "disp":"7:38"},
		{"title":"How recurrent neural nets work", "m":9, "s":06, "disp":"9:06"},
		{"title":"Training RNNs on text (character sequences)", "m":11, "s":32, "disp":"11:32"},
		{"title":"RNNs and sequence-to-sequence", "m":20, "s":05, "disp":"20:05"},
		{"title":"Image captioning", "m":22, "s":25, "disp":"22:25"},
		{"title":"Advanced architectures and applications", "m":28, "s":12, "disp":"28:12"},
		{"title":"Tutorial: text generation via torch-rnn", "m":34, "s":20, "disp":"34:20"},
		{"title":"Tutorial: style transfer via neural-style", "m":63, "s":31, "disp":"1:03:31"}
	],
	"summary": [
		"How recurrent neural networks work",
		"Applications, architectures, and case studies of RNNs",
		"Tutorial: generating text",
		"Tutorial: style transfer"
	]
},{
	"youtube_id": "CRM7HYZYHvo",
	"title": "Game AI and deep reinforcement learning",
	"date": "4/28/2016",
	"thumbnail": "/images/classes/itp-S16/thumbnail_06.png",
	"dropbox": "https://www.dropbox.com/s/llzkkc9fj926qlr/ml4a%20%40%20itp-nyu%20--%2006%20reinforcement%20learning%2C%20games%2C%20generative%20models.mp4?dl=1",
	"bookmarks": [
		{"title":"The whole class \"in 10 minutes\"", "m":14, "s":33, "disp":"14:33"},
		{"title":"Autoencoders", "m":43, "s":03, "disp":"43:03"},
		{"title":"Generative adversarial networks", "m":53, "s":58, "disp":"53:58"},
		{"title":"Game AI + reinforcement learning", "m":64, "s":59, "disp":"1:04:59"},
		{"title":"Convnets mastering atari games", "m":74, "s":51, "disp":"1:14:51"},
		{"title":"States, actions, and rewards, Q-learning", "m":88, "s":52, "disp":"1:28:52"},
		{"title":"Super mario craziness, computer tic-tac-toe", "m":100, "s":48, "disp":"1:40:48"},
		{"title":"Computer chess: how DeepBlue works", "m":109, "s":59, "disp":"1:49:59"},
		{"title":"Computer go: how AlphaGo works", "m":124, "s":05, "disp":"2:04:05"}
	],
	"summary": [
		"Generative models (autoencoders + GANs)",
		"Game AI + reinforcement learning",
		"Convnets mastering atari games",
		"Computer chess & computer go, how AlphaGo works"
	]
},{
	"youtube_id": "7wXnI2poifI",
	"title": "The Neural Aesthetic",
	"date": "6/4/2016",
	"thumbnail": "/images/classes/itp-S16/thumbnail_07.png",
	"dropbox": "https://www.dropbox.com/s/ilqrbn8i4n66sv7/ml4a%20%40%20itp-nyu%20--%20the%20neural%20aesthetic%206.4.mp4?dl=1",
	"bookmarks": [
		{"title":"ML circa 2010 + music info retrieval", "m":11, "s":10, "disp":"11:10"},
		{"title":"From perceptrons to deep neural nets", "m":27, "s":25, "disp":"27:25"},
		{"title":"Convolutional neural networks", "m":64, "s":12, "disp":"1:04:12"},
		{"title":"Convolution demo end to end", "m":81, "s":20, "disp":"1:21:20"},
		{"title":"Visualizing activations and synthesizing classes", "m":94, "s":23, "disp":"1:34:23"},
		{"title":"Deepdream and style transfer", "m":105, "s":35, "disp":"1:45:35"},
		{"title":"Video style transfer with optical flow", "m":124, "s":08, "disp":"2:04:08"},
		{"title":"t-SNE on images and text", "m":132, "s":41, "disp":"2:12:41"},
		{"title":"Generative models + DCGANs", "m":142, "s":19, "disp":"2:22:19"},
		{"title":"Recurrent neural networks, game AI + RL", "m":151, "s":39, "disp":"2:31:39"},
		{"title":"Recent developments + real-time style transfer", "m":160, "s":48, "disp":"2:40:48"}
	],
	"summary": [
		"Theory of neural networks",
		"Applications of convnets (deepdream, style transfer, etc)",
		"Survey of sub-topics and practical resources",
		"ml4a and how to keep up with the field"
	]
}]
}